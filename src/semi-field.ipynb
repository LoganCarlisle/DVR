{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install warp-lang","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-16T03:08:05.805444Z","iopub.execute_input":"2025-10-16T03:08:05.805901Z","iopub.status.idle":"2025-10-16T03:08:16.479343Z","shell.execute_reply.started":"2025-10-16T03:08:05.805875Z","shell.execute_reply":"2025-10-16T03:08:16.478550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warp as wp\nimport numpy as np\nimport torch\n\nwp.init()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T03:08:16.480735Z","iopub.execute_input":"2025-10-16T03:08:16.481076Z","iopub.status.idle":"2025-10-16T03:08:21.190710Z","shell.execute_reply.started":"2025-10-16T03:08:16.481053Z","shell.execute_reply":"2025-10-16T03:08:21.189831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warp as wp\nimport numpy as np\nimport torch\n\n# Initialize Warp\nwp.init()\n\n@wp.struct\nclass Drop:\n    position: wp.vec3\n    radius: wp.float32\n    weight: wp.float32\n    energy: wp.float32\n    sigma: wp.float32\n\n@wp.struct\nclass Ray:\n    origin: wp.vec3\n    dir: wp.vec3\n\n# --- Differentiable Influence Function ---\n\n@wp.func\ndef influence_func(sample_pos: wp.vec3, drop_pos: wp.vec3, sigma: wp.float32):\n    dist_sq = wp.length_sq(sample_pos - drop_pos)\n    sigma_sq = sigma * sigma\n    return wp.exp(-dist_sq / (2.0 * sigma_sq + 1e-8))\n\n# --- Volumetric Tracing Kernel with HashGrid ---\n\n@wp.kernel\ndef volumetric_trace(\n    # Scene Data\n    grid: wp.uint64, # CHANGED: We now use a hash grid ID\n    drop_positions: wp.array(dtype=wp.vec3),\n    drop_learnable_params: wp.array(dtype=wp.float32, ndim=2),\n\n    # Input/Output\n    initial_rays: wp.array(dtype=Ray),\n    outputs: wp.array(dtype=wp.float32),\n\n    # Kernel Parameters\n    num_steps: wp.int32,\n    step_size: wp.float32,\n    query_radius: wp.float32\n):\n    tid = wp.tid()\n    ray = initial_rays[tid]\n    accumulated_radiance = wp.float32(0.0)\n\n    for i in range(num_steps):\n        t = wp.float32(i) * step_size\n        sample_pos = ray.origin + ray.dir * t\n\n        # FIXED: Use the correct hash grid query function\n        query = wp.hash_grid_query(grid, sample_pos, query_radius)\n        candidate_index = wp.int32(0)\n        \n        local_radiance = wp.float32(0.0)\n\n        # Loop over neighbors found by the query\n        while wp.hash_grid_query_next(query, candidate_index):\n            drop_weight = drop_learnable_params[candidate_index, 0]\n            drop_energy = drop_learnable_params[candidate_index, 1]\n            drop_sigma  = drop_learnable_params[candidate_index, 2]\n\n            influence = influence_func(sample_pos, drop_positions[candidate_index], drop_sigma)\n            contribution = influence * drop_weight * drop_energy\n            local_radiance += contribution\n        \n        accumulated_radiance += local_radiance * step_size\n    \n    outputs[tid] = accumulated_radiance\n@wp.kernel\ndef calculate_sparsity_cost(\n    # Same inputs as the main kernel to trace the same paths\n    grid: wp.uint64,\n    initial_rays: wp.array(dtype=Ray),\n    \n    # Output\n    total_neighbor_interactions: wp.array(dtype=wp.int32),\n\n    # Kernel Parameters\n    num_steps: wp.int32,\n    step_size: wp.float32,\n    query_radius: wp.float32\n):\n    tid = wp.tid()\n    ray = initial_rays[tid]\n\n    for i in range(num_steps):\n        t = wp.float32(i) * step_size\n        sample_pos = ray.origin + ray.dir * t\n\n        query = wp.hash_grid_query(grid, sample_pos, query_radius)\n        candidate_index = wp.int32(0)\n        \n        # Loop over neighbors and just count them\n        while wp.hash_grid_query_next(query, candidate_index):\n            # Atomically increment a global counter for each interaction\n            wp.atomic_add(total_neighbor_interactions, 0, 1)\n\n#main area\n\n# Sim step\nnum_drops = 400\nnum_initial_rays = 4096\ntraining_steps = 150\ndevice = wp.get_preferred_device()\ntorch_device = torch.device('cuda' if wp.get_device(device).is_cuda else 'cpu')\n\n# create drops\nrng = np.random.default_rng(42)\npositions_np = (rng.random(size=(num_drops, 3), dtype=np.float32) - 0.5) * 8.0\npositions_np[:, 2] += 5.0\npositions_device = wp.array(positions_np, dtype=wp.vec3, device=device)\n\nprint(\"Building HashGrid...\")\ngrid_cell_size = 2.0 \ngrid = wp.HashGrid(dim_x=128, dim_y=128, dim_z=128, device=device)\n# The grid needs to be built with the particle positions\ngrid.build(points=positions_device, radius=grid_cell_size)\nprint(f\"HashGrid built for {num_drops} drops.\")\n\n#drop properties\ninitial_weights = (rng.random(size=(num_drops, 1), dtype=np.float32) - 0.5) * 0.1\ninitial_energies = np.ones((num_drops, 1), dtype=np.float32)\ninitial_sigmas = np.full((num_drops, 1), 0.5, dtype=np.float32)\nlearnable_data_np = np.hstack([initial_weights, initial_energies, initial_sigmas])\nlearnable_params_tensor = torch.tensor(learnable_data_np, requires_grad=True, device=torch_device)\n\noptimizer = torch.optim.Adam([learnable_params_tensor], lr=0.01)\nloss_fn = torch.nn.MSELoss()\n\n# fake data\ny_true_np = np.zeros(num_initial_rays, dtype=np.float32)\nnum_rays_side = int(np.sqrt(num_initial_rays))\nfor j in range(num_rays_side):\n    for i in range(num_rays_side):\n        idx = j * num_rays_side + i\n        if idx >= num_initial_rays: continue\n        u = (i / (num_rays_side - 1) - 0.5) * 2.0\n        v = (j / (num_rays_side - 1) - 0.5) * 2.0\n        distance_sq = u*u + v*v\n        sigma_target = 0.5\n        y_true_np[idx] = 5.0 * np.exp(-distance_sq / (2.0 * sigma_target**2.0))\ny_true_tensor = torch.tensor(y_true_np, device=torch_device)\n\n# initial rays\ninitial_rays_np = np.empty(num_initial_rays, dtype=Ray.numpy_dtype())\nfor j in range(num_rays_side):\n    for i in range(num_rays_side):\n        idx = j * num_rays_side + i\n        if idx >= num_initial_rays: continue\n        ox = (i / (num_rays_side - 1) - 0.5) * 5.0\n        oy = (j / (num_rays_side - 1) - 0.5) * 5.0\n        initial_rays_np[idx]['origin'] = (ox, oy, -1.0)\n        initial_rays_np[idx]['dir'] = (0.0, 0.0, 1.0)\ninitial_rays_wp = wp.array(initial_rays_np, dtype=Ray, device=device)\n\n\nprint(f\"been training for like {training_steps} steps ---\")\n\n# sparse params\nlambda_l1 = 1e-4 \n\nfor step in range(training_steps):\n    optimizer.zero_grad()\n    \n    learnable_params_wp = wp.from_torch(learnable_params_tensor)\n    outputs_tensor = torch.zeros(num_initial_rays, dtype=torch.float32, device=torch_device)\n    outputs_wp = wp.from_torch(outputs_tensor)\n\n    # forward pass\n    tape = wp.Tape()\n    with tape:\n        wp.launch(\n            kernel=volumetric_trace,\n            dim=num_initial_rays,\n            inputs=[\n                grid.id,\n                positions_device,\n                learnable_params_wp,\n                initial_rays_wp,\n                outputs_wp,\n                64,    # num_steps\n                0.2,   # step_size\n                1.0    # query_radius\n            ],\n            device=device\n        )\n\n    # main render loss\n    rendering_loss = loss_fn(outputs_tensor, y_true_tensor)\n    drop_weights = learnable_params_tensor[:, 0]\n    l1_loss = lambda_l1 * torch.abs(drop_weights).sum()\n    \n    # aux loss\n    total_loss = rendering_loss + l1_loss\n\n    # back pass\n    # \n    seed_grad_tensor = (2.0 / num_initial_rays) * (outputs_tensor - y_true_tensor)\n    tape.backward(grads={outputs_wp: wp.from_torch(seed_grad_tensor)})\n    \n    # Copy the Warp gradients to the PyTorch tensor\n    learnable_params_tensor.grad = wp.to_torch(learnable_params_wp.grad)\n    \n    \n    l1_loss.backward()\n\n    # --- 5. Optimizer Step ---\n    optimizer.step()\n    \n    if step % 10 == 0 or step == training_steps - 1:\n        print(f\"Step {step:03d}, Rendering Loss: {rendering_loss.item():.6f}, L1 Loss: {l1_loss.item():.6f}\")\n\nprint(\"\\n--- Training complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T04:05:09.445724Z","iopub.execute_input":"2025-10-16T04:05:09.446235Z","iopub.status.idle":"2025-10-16T04:05:10.886267Z","shell.execute_reply.started":"2025-10-16T04:05:09.446214Z","shell.execute_reply":"2025-10-16T04:05:10.885681Z"}},"outputs":[{"name":"stdout","text":"Building HashGrid...\nHashGrid built for 400 drops.\n\n--- Starting Training for 150 steps ---\nStep 000, Rendering Loss: 4.749850, L1 Loss: 0.001019\nStep 010, Rendering Loss: 1.325285, L1 Loss: 0.002278\nStep 020, Rendering Loss: 0.351572, L1 Loss: 0.002482\nStep 030, Rendering Loss: 0.073063, L1 Loss: 0.002218\nStep 040, Rendering Loss: 0.052650, L1 Loss: 0.002323\nStep 050, Rendering Loss: 0.023236, L1 Loss: 0.002354\nStep 060, Rendering Loss: 0.010697, L1 Loss: 0.002223\nStep 070, Rendering Loss: 0.006464, L1 Loss: 0.002115\nStep 080, Rendering Loss: 0.003927, L1 Loss: 0.001986\nStep 090, Rendering Loss: 0.002607, L1 Loss: 0.001880\nStep 100, Rendering Loss: 0.001990, L1 Loss: 0.001803\nStep 110, Rendering Loss: 0.001588, L1 Loss: 0.001745\nStep 120, Rendering Loss: 0.001333, L1 Loss: 0.001690\nStep 130, Rendering Loss: 0.001145, L1 Loss: 0.001641\nStep 140, Rendering Loss: 0.000996, L1 Loss: 0.001604\nStep 149, Rendering Loss: 0.000889, L1 Loss: 0.001573\n\n--- Training complete ---\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import warp as wp\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nwp.init()\n\n@wp.struct\nclass Ray:\n    origin: wp.vec3\n    dir: wp.vec3\n\n\n@wp.func\ndef influence_func(sample_pos: wp.vec3, drop_pos: wp.vec3, sigma: wp.float32):\n    \"\"\"Calculates the influence of a drop at a sample point.\"\"\"\n    dist_sq = wp.length_sq(sample_pos - drop_pos)\n    sigma_sq = sigma * sigma\n    return wp.exp(-dist_sq / (2.0 * sigma_sq + 1e-9))\n\n\n@wp.kernel\ndef volumetric_trace(\n    # Scene Data\n    grid: wp.uint64,\n    drop_positions: wp.array(dtype=wp.vec3),\n    drop_learnable_params: wp.array(dtype=wp.float32, ndim=2),\n\n    # Input/Output\n    initial_rays: wp.array(dtype=Ray),\n    outputs: wp.array(dtype=wp.float32),\n\n    # Kernel Parameters\n    num_steps: wp.int32,\n    step_size: wp.float32,\n    query_radius: wp.float32\n):\n    \"\"\"Traces rays through the volume and accumulates radiance.\"\"\"\n    tid = wp.tid()\n    ray = initial_rays[tid]\n    accumulated_radiance = wp.float32(0.0)\n\n    for i in range(num_steps):\n        t = wp.float32(i) * step_size\n        sample_pos = ray.origin + ray.dir * t\n\n        query = wp.hash_grid_query(grid, sample_pos, query_radius)\n        candidate_index = wp.int32(0)\n        \n        local_radiance = wp.float32(0.0)\n\n        while wp.hash_grid_query_next(query, candidate_index):\n            drop_weight = wp.clamp(drop_learnable_params[candidate_index, 0], -1.0, 1.0)\n            drop_energy = wp.clamp(drop_learnable_params[candidate_index, 1], 0.0, 5.0)\n            drop_sigma  = wp.clamp(drop_learnable_params[candidate_index, 2], 0.01, 2.0)\n\n            influence = influence_func(sample_pos, drop_positions[candidate_index], drop_sigma)\n            contribution = influence * drop_weight * drop_energy\n            local_radiance += contribution\n        \n        accumulated_radiance += local_radiance * step_size\n    \n    outputs[tid] = accumulated_radiance\n\n\nclass VolumetricSplattingLayer(nn.Module):\n    \"\"\"\n    A plug-and-play neural network layer for volumetric rendering.\n    Manages its own state of \"drops\" and handles rendering, densification, and pruning.\n    \"\"\"\n    def __init__(self, initial_positions, initial_learnable_params, device,\n                 densify_start_step=100, densify_interval=100,\n                 prune_threshold_weight=0.005, densify_grad_threshold=0.001,\n                 split_threshold_sigma=0.5, ema_beta=0.9):\n        super().__init__()\n        self.device = 'cuda'\n                self.positions = nn.Parameter(torch.tensor(initial_positions, device=self.device))\n        self.learnable_params = nn.Parameter(torch.tensor(initial_learnable_params, device=self.device))\n\n        self.densify_start_step = densify_start_step\n        self.densify_interval = densify_interval\n        self.prune_threshold_weight = prune_threshold_weight\n        self.densify_grad_threshold = densify_grad_threshold\n        self.split_threshold_sigma = split_threshold_sigma\n        \n        self.ema_beta = ema_beta\n        self.position_grad_ema = torch.zeros_like(self.positions)\n\n    def forward(self, initial_rays_wp: wp.array):\n        \"\"\"\n        Performs the forward pass: renders the volume for the given rays.\n        \"\"\"\n        num_initial_rays = initial_rays_wp.shape[0]\n        \n        # Rebuild HashGrid at every step since positions are learnable\n        # Store these warp arrays as attributes to be accessed in the backward pass\n        self.current_positions_wp = wp.from_torch(self.positions, dtype=wp.vec3)\n        grid = wp.HashGrid(dim_x=128, dim_y=128, dim_z=128, device=self.device)\n        grid.build(points=self.current_positions_wp, radius=2.0)\n        \n        self.learnable_params_wp = wp.from_torch(self.learnable_params)\n        outputs_tensor = torch.zeros(num_initial_rays, dtype=torch.float32, device=self.device)\n        self.outputs_wp = wp.from_torch(outputs_tensor)\n\n        \n        self.tape = wp.Tape()\n        with self.tape:\n            wp.launch(\n                kernel=volumetric_trace,\n                dim=num_initial_rays,\n                inputs=[\n                    grid.id,\n                    self.current_positions_wp,\n                    self.learnable_params_wp,\n                    initial_rays_wp,\n                    self.outputs_wp,\n                    64, 0.2, 1.5 # num_steps, step_size, query_radius\n                ],\n                device=self.device\n            )\n        \n        return outputs_tensor\n\n    @torch.no_grad()\n    def update_state(self, step: int, optimizer: torch.optim.Optimizer):\n        \"\"\"\n        Updates the layer's state by pruning and densifying drops.\n        This should be called from the main training loop.\n        Returns True if the optimizer needs to be reset.\n        \"\"\"\n        if step <= self.densify_start_step or step % self.densify_interval != 0:\n            return False\n\n        if self.positions.grad is None:\n            return False\n\n        # Update gradient EMA for stable densification ---\n        self.position_grad_ema = self.ema_beta * self.position_grad_ema + \\\n                                 (1.0 - self.ema_beta) * self.positions.grad\n        \n        pos_grads_magnitude = torch.norm(self.position_grad_ema, dim=1)\n        \n        print(f\"--- Step {step:03d}: Densification ---\")\n        print(f\"Max position grad magnitude (EMA): {pos_grads_magnitude.max().item():.6f}\")\n\n        # prune\n        prune_mask = torch.abs(self.learnable_params[:, 0]) > self.prune_threshold_weight\n        n_pruned = self.positions.shape[0] - prune_mask.sum().item()\n        \n        if n_pruned > 0:\n            self.positions.data = self.positions.data[prune_mask]\n            self.learnable_params.data = self.learnable_params.data[prune_mask]\n            pos_grads_magnitude = pos_grads_magnitude[prune_mask]\n            self.position_grad_ema = self.position_grad_ema[prune_mask]\n\n        # splitting\n        split_mask = (self.learnable_params[:, 2] > self.split_threshold_sigma) & (pos_grads_magnitude > self.densify_grad_threshold)\n        n_split = 0\n        if split_mask.any():\n            n_split = split_mask.sum().item()\n            split_positions = self.positions.data[split_mask]\n            split_learnables = self.learnable_params.data[split_mask]\n\n            new_positions = split_positions.repeat(2, 1)\n            new_learnables = split_learnables.repeat(2, 1)\n            new_learnables[:, 2] *= 0.7\n            new_learnables[:, 0] *= 0.7 \n            \n            stdev = torch.sqrt(new_learnables[:n_split, 2])\n            mean = torch.zeros_like(stdev)\n            offset_dir = self.positions.grad[prune_mask if n_pruned > 0 else torch.ones_like(prune_mask, dtype=torch.bool)][split_mask]\n            offset = torch.normal(mean, stdev).unsqueeze(1) * (offset_dir / (torch.norm(offset_dir, dim=1, keepdim=True) + 1e-9))\n\n            new_positions[:n_split] += offset\n            new_positions[n_split:] -= offset\n            \n            keep_mask = ~split_mask\n            self.positions.data = torch.cat((self.positions.data[keep_mask], new_positions), dim=0)\n            self.learnable_params.data = torch.cat((self.learnable_params.data[keep_mask], new_learnables), dim=0)\n\n            split_grads_magnitude = pos_grads_magnitude[split_mask].repeat(2)\n            pos_grads_magnitude = torch.cat((pos_grads_magnitude[keep_mask], split_grads_magnitude), dim=0)\n\n            split_grad_ema = self.position_grad_ema[split_mask].repeat(2, 1)\n            self.position_grad_ema = torch.cat((self.position_grad_ema[keep_mask], split_grad_ema), dim=0)\n\n        # cloning\n        clone_mask = (self.learnable_params[:, 2] <= self.split_threshold_sigma) & (pos_grads_magnitude > self.densify_grad_threshold)\n        n_cloned = 0\n        if clone_mask.any():\n            n_cloned = clone_mask.sum().item()\n            clone_positions = self.positions.data[clone_mask]\n            clone_learnables = self.learnable_params.data[clone_mask]\n\n            self.learnable_params.data[clone_mask, 0] /= 2.0\n            \n            self.positions.data = torch.cat((self.positions.data, clone_positions), dim=0)\n            self.learnable_params.data = torch.cat((self.learnable_params.data, clone_learnables), dim=0)\n            self.position_grad_ema = torch.cat((self.position_grad_ema, self.position_grad_ema[clone_mask]), dim=0)\n\n\n        if n_pruned > 0 or n_split > 0 or n_cloned > 0:\n            print(f\"Pruned: {n_pruned}, Split: {n_split}, Cloned: {n_cloned}.\")\n            return True # Optimizer needs reset\n            \n        return False\n\n\n\n# Simulation setup\nnum_drops_initial = 400\nnum_initial_rays = 4096\ntraining_steps = 300\ndevice = wp.get_preferred_device()\ntorch_device = 'cuda' if wp.get_device(device).is_cuda else 'cpu'\nlambda_l1 = 1e-4\n\n# init drop data\nrng = np.random.default_rng(42)\npositions_np = (rng.random(size=(num_drops_initial, 3), dtype=np.float32) - 0.5) * 8.0\npositions_np[:, 2] += 5.0\ninitial_weights = (rng.random(size=(num_drops_initial, 1), dtype=np.float32) - 0.5) * 0.1\ninitial_energies = np.ones((num_drops_initial, 1), dtype=np.float32)\ninitial_sigmas = np.full((num_drops_initial, 1), 0.5, dtype=np.float32)\nlearnable_data_np = np.hstack([initial_weights, initial_energies, initial_sigmas])\n\n#fake data and rays\ny_true_np = np.zeros(num_initial_rays, dtype=np.float32)\nnum_rays_side = int(np.sqrt(num_initial_rays))\nfor j in range(num_rays_side):\n    for i in range(num_rays_side):\n        idx = j * num_rays_side + i\n        if idx >= num_initial_rays: continue\n        u, v = (i / (num_rays_side - 1) - 0.5) * 2.0, (j / (num_rays_side - 1) - 0.5) * 2.0\n        y_true_np[idx] = 5.0 * np.exp(-(u*u + v*v) / (2.0 * 0.5**2.0))\ny_true_tensor = torch.tensor(y_true_np, device=torch_device)\n\ninitial_rays_np = np.empty(num_initial_rays, dtype=Ray.numpy_dtype())\nfor j in range(num_rays_side):\n    for i in range(num_rays_side):\n        idx = j * num_rays_side + i\n        if idx >= num_initial_rays: continue\n        ox, oy = (i / (num_rays_side - 1) - 0.5) * 5.0, (j / (num_rays_side - 1) - 0.5) * 5.0\n        initial_rays_np[idx]['origin'], initial_rays_np[idx]['dir'] = (ox, oy, -1.0), (0.0, 0.0, 1.0)\ninitial_rays_wp = wp.array(initial_rays_np, dtype=Ray, device=device)\n\nmodel = VolumetricSplattingLayer(positions_np, learnable_data_np, device).to(torch_device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nprint(f\"\\n training for like {training_steps} steps ---\")\n\nfor step in range(training_steps):\n    optimizer.zero_grad()\n    #forward\n    outputs_tensor = model(initial_rays_wp)\n    \n    # loss calc\n    rendering_loss = F.mse_loss(outputs_tensor, y_true_tensor)\n    l1_loss = lambda_l1 * torch.abs(model.learnable_params[:, 0]).sum()\n    total_loss = rendering_loss + l1_loss\n    \n    # back pass\n    # get rend grads from warp\n    seed_grad_tensor = (2.0 / outputs_tensor.numel()) * (outputs_tensor - y_true_tensor)\n    seed_grad_wp = wp.from_torch(seed_grad_tensor.contiguous())\n    # Use the output warp array stored as a model attribute as the key\n    model.tape.backward(grads={model.outputs_wp: seed_grad_wp})\n    \n    # Retrieve gradients using the input warp arrays (also stored as attributes)\n    model.learnable_params.grad = wp.to_torch(model.tape.gradients[model.learnable_params_wp])\n    model.positions.grad = wp.to_torch(model.tape.gradients[model.current_positions_wp])\n    \n    # Manually add L1 grads to avoid autograd issues with in-place updates\n    with torch.no_grad():\n        # Gradient of L1 loss is lambda * sign(parameter)\n        l1_grad_weights = lambda_l1 * torch.sign(model.learnable_params.data[:, 0])\n        \n        # Create a zero tensor with the same shape as the full gradient\n        l1_grad_full = torch.zeros_like(model.learnable_params.grad)\n        \n        # Place the weight gradients in the first column\n        l1_grad_full[:, 0] = l1_grad_weights\n        \n        # Accumulate the gradients\n        model.learnable_params.grad += l1_grad_full\n\n    # optimizer step\n    optimizer.step()\n\n    # prune and densiffy \n    if model.update_state(step, optimizer):\n        # If drops were added/removed, we must reset the optimizer's state\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n    if step % 10 == 0 or step == training_steps - 1:\n        print(f\"Step {step:03d}, Total Loss: {total_loss.item():.6f} (Render: {rendering_loss.item():.6f}, L1: {l1_loss.item():.6f}), Num Drops: {model.positions.shape[0]}\")\n\nprint(\"\\n--- Training complete ---\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T04:52:50.866093Z","iopub.execute_input":"2025-10-16T04:52:50.866642Z","iopub.status.idle":"2025-10-16T04:52:55.995124Z","shell.execute_reply.started":"2025-10-16T04:52:50.866606Z","shell.execute_reply":"2025-10-16T04:52:55.994337Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Training for 300 steps ---\nStep 000, Total Loss: 4.751473 (Render: 4.750454, L1: 0.001019), Num Drops: 400\nStep 010, Total Loss: 1.061185 (Render: 1.058930, L1: 0.002255), Num Drops: 400\nStep 020, Total Loss: 0.249210 (Render: 0.246908, L1: 0.002302), Num Drops: 400\nStep 030, Total Loss: 0.112066 (Render: 0.110066, L1: 0.002001), Num Drops: 400\nStep 040, Total Loss: 0.023191 (Render: 0.020962, L1: 0.002229), Num Drops: 400\nStep 050, Total Loss: 0.013817 (Render: 0.011561, L1: 0.002256), Num Drops: 400\nStep 060, Total Loss: 0.007593 (Render: 0.005451, L1: 0.002142), Num Drops: 400\nStep 070, Total Loss: 0.005473 (Render: 0.003422, L1: 0.002050), Num Drops: 400\nStep 080, Total Loss: 0.004150 (Render: 0.002178, L1: 0.001972), Num Drops: 400\nStep 090, Total Loss: 0.003455 (Render: 0.001541, L1: 0.001914), Num Drops: 400\nStep 100, Total Loss: 0.002929 (Render: 0.001078, L1: 0.001851), Num Drops: 400\nStep 110, Total Loss: 0.002604 (Render: 0.000798, L1: 0.001806), Num Drops: 400\nStep 120, Total Loss: 0.002375 (Render: 0.000600, L1: 0.001775), Num Drops: 400\nStep 130, Total Loss: 0.002211 (Render: 0.000464, L1: 0.001748), Num Drops: 400\nStep 140, Total Loss: 0.002093 (Render: 0.000367, L1: 0.001726), Num Drops: 400\nStep 150, Total Loss: 0.002003 (Render: 0.000296, L1: 0.001707), Num Drops: 400\nStep 160, Total Loss: 0.001931 (Render: 0.000244, L1: 0.001687), Num Drops: 400\nStep 170, Total Loss: 0.001875 (Render: 0.000206, L1: 0.001669), Num Drops: 400\nStep 180, Total Loss: 0.001829 (Render: 0.000176, L1: 0.001653), Num Drops: 400\nStep 190, Total Loss: 0.001791 (Render: 0.000152, L1: 0.001639), Num Drops: 400\n--- Step 200: Densification ---\nMax position grad magnitude (EMA): 0.000009\nPruned: 205, Split: 0, Cloned: 0.\nStep 200, Total Loss: 0.001756 (Render: 0.000133, L1: 0.001623), Num Drops: 195\nStep 210, Total Loss: 0.004052 (Render: 0.002603, L1: 0.001450), Num Drops: 195\nStep 220, Total Loss: 0.001662 (Render: 0.000241, L1: 0.001421), Num Drops: 195\nStep 230, Total Loss: 0.001616 (Render: 0.000226, L1: 0.001389), Num Drops: 195\nStep 240, Total Loss: 0.001517 (Render: 0.000155, L1: 0.001361), Num Drops: 195\nStep 250, Total Loss: 0.001375 (Render: 0.000034, L1: 0.001341), Num Drops: 195\nStep 260, Total Loss: 0.001343 (Render: 0.000029, L1: 0.001314), Num Drops: 195\nStep 270, Total Loss: 0.001311 (Render: 0.000024, L1: 0.001288), Num Drops: 195\nStep 280, Total Loss: 0.001279 (Render: 0.000017, L1: 0.001262), Num Drops: 195\nStep 290, Total Loss: 0.001252 (Render: 0.000015, L1: 0.001237), Num Drops: 195\nStep 299, Total Loss: 0.001227 (Render: 0.000013, L1: 0.001214), Num Drops: 195\n\n--- Training complete ---\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import warp as wp\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n# --- (Your existing Warp structs and kernels remain unchanged) ---\n# Initialize Warp\nwp.init()\n\n@wp.struct\nclass Ray:\n    origin: wp.vec3\n    dir: wp.vec3\n\n@wp.func\ndef influence_func(sample_pos: wp.vec3, drop_pos: wp.vec3, sigma: wp.float32):\n    \"\"\"Calculates the influence of a drop at a sample point.\"\"\"\n    dist_sq = wp.length_sq(sample_pos - drop_pos)\n    sigma_sq = sigma * sigma\n    return wp.exp(-dist_sq / (2.0 * sigma_sq + 1e-9))\n\n@wp.kernel\ndef volumetric_trace(\n    # Scene Data\n    grid: wp.uint64,\n    drop_positions: wp.array(dtype=wp.vec3),\n    drop_learnable_params: wp.array(dtype=wp.float32, ndim=2),\n\n    # Input/Output\n    initial_rays: wp.array(dtype=Ray),\n    outputs: wp.array(dtype=wp.float32),\n\n    # Kernel Parameters\n    num_steps: wp.int32,\n    step_size: wp.float32,\n    query_radius: wp.float32\n):\n    \"\"\"Traces rays through the volume and accumulates radiance.\"\"\"\n    tid = wp.tid()\n    ray = initial_rays[tid]\n    accumulated_radiance = wp.float32(0.0)\n\n    for i in range(num_steps):\n        t = wp.float32(i) * step_size\n        sample_pos = ray.origin + ray.dir * t\n\n        query = wp.hash_grid_query(grid, sample_pos, query_radius)\n        candidate_index = wp.int32(0)\n        \n        local_radiance = wp.float32(0.0)\n\n        while wp.hash_grid_query_next(query, candidate_index):\n            drop_weight = wp.clamp(drop_learnable_params[candidate_index, 0], -1.0, 1.0)\n            drop_energy = wp.clamp(drop_learnable_params[candidate_index, 1], 0.0, 5.0)\n            drop_sigma  = wp.clamp(drop_learnable_params[candidate_index, 2], 0.01, 2.0)\n\n            influence = influence_func(sample_pos, drop_positions[candidate_index], drop_sigma)\n            contribution = influence * drop_weight * drop_energy\n            local_radiance += contribution\n        \n        accumulated_radiance += local_radiance * step_size\n    \n    outputs[tid] = accumulated_radiance\n\n# --- (Your VolumetricSplattingLayer remains mostly unchanged) ---\nclass VolumetricSplattingLayer(nn.Module):\n    \"\"\"\n    A plug-and-play neural network layer for volumetric rendering.\n    Manages its own state of \"drops\" and handles rendering, densification, and pruning.\n    \"\"\"\n    def __init__(self, initial_positions, initial_learnable_params, device,\n                 densify_start_step=500, densify_interval=100,\n                 prune_threshold_weight=0.005, densify_grad_threshold=0.0005,\n                 split_threshold_sigma=0.5, ema_beta=0.9):\n        super().__init__()\n        self.device = 'cuda'\n        \n        # --- Register drops as learnable parameters ---\n        self.positions = nn.Parameter(torch.tensor(initial_positions, device=self.device))\n        self.learnable_params = nn.Parameter(torch.tensor(initial_learnable_params, device=self.device))\n\n        # --- Densification and Pruning state ---\n        self.densify_start_step = densify_start_step\n        self.densify_interval = densify_interval\n        self.prune_threshold_weight = prune_threshold_weight\n        self.densify_grad_threshold = densify_grad_threshold\n        self.split_threshold_sigma = split_threshold_sigma\n        \n        # --- EMA for stable gradient-based densification ---\n        self.ema_beta = ema_beta\n        self.position_grad_ema = torch.zeros_like(self.positions)\n\n    def forward(self, initial_rays_wp: wp.array):\n        num_initial_rays = initial_rays_wp.shape[0]\n        \n        # Store these warp arrays as attributes to be accessed in the backward pass\n        self.current_positions_wp = wp.from_torch(self.positions, dtype=wp.vec3)\n        grid = wp.HashGrid(dim_x=128, dim_y=128, dim_z=128, device=self.device)\n        grid.build(points=self.current_positions_wp, radius=2.0)\n        \n        self.learnable_params_wp = wp.from_torch(self.learnable_params)\n        outputs_tensor = torch.zeros(num_initial_rays, dtype=torch.float32, device=self.device, requires_grad=True)\n        self.outputs_wp = wp.from_torch(outputs_tensor)\n\n        self.tape = wp.Tape()\n        with self.tape:\n            wp.launch(\n                kernel=volumetric_trace,\n                dim=num_initial_rays,\n                inputs=[\n                    grid.id,\n                    self.current_positions_wp,\n                    self.learnable_params_wp,\n                    initial_rays_wp,\n                    self.outputs_wp,\n                    32, 0.25, 1.5 # num_steps, step_size, query_radius\n                ],\n                device=self.device\n            )\n        \n        return outputs_tensor\n\n    @torch.no_grad()\n    def update_state(self, step: int):\n        if step <= self.densify_start_step or step % self.densify_interval != 0:\n            return False\n\n        if self.positions.grad is None:\n            return False\n\n        self.position_grad_ema = self.ema_beta * self.position_grad_ema + \\\n                                 (1.0 - self.ema_beta) * self.positions.grad\n        \n        pos_grads_magnitude = torch.norm(self.position_grad_ema, dim=1)\n        \n        # --- 1. Pruning ---\n        prune_mask = torch.abs(self.learnable_params[:, 0]) > self.prune_threshold_weight\n        n_pruned = self.positions.shape[0] - prune_mask.sum().item()\n        \n        if n_pruned > 0:\n            self.positions.data = self.positions.data[prune_mask]\n            self.learnable_params.data = self.learnable_params.data[prune_mask]\n            pos_grads_magnitude = pos_grads_magnitude[prune_mask]\n            self.position_grad_ema = self.position_grad_ema[prune_mask]\n\n        # --- 2. Densification (Splitting) ---\n        split_mask = (self.learnable_params[:, 2] > self.split_threshold_sigma) & (pos_grads_magnitude > self.densify_grad_threshold)\n        n_split = 0\n        if split_mask.any():\n            n_split = split_mask.sum().item()\n            split_positions = self.positions.data[split_mask]\n            split_learnables = self.learnable_params.data[split_mask]\n\n            new_positions = split_positions.repeat(2, 1)\n            new_learnables = split_learnables.repeat(2, 1)\n            new_learnables[:, 2] *= 0.7\n            new_learnables[:, 0] *= 0.7 \n            \n            stdev = torch.sqrt(new_learnables[:n_split, 2])\n            mean = torch.zeros_like(stdev)\n            offset_dir = self.positions.grad[prune_mask if n_pruned > 0 else torch.ones_like(prune_mask, dtype=torch.bool)][split_mask]\n            offset = torch.normal(mean, stdev).unsqueeze(1) * (offset_dir / (torch.norm(offset_dir, dim=1, keepdim=True) + 1e-9))\n\n            new_positions[:n_split] += offset\n            new_positions[n_split:] -= offset\n            \n            keep_mask = ~split_mask\n            self.positions.data = torch.cat((self.positions.data[keep_mask], new_positions), dim=0)\n            self.learnable_params.data = torch.cat((self.learnable_params.data[keep_mask], new_learnables), dim=0)\n\n            split_grad_ema = self.position_grad_ema[split_mask].repeat(2, 1)\n            self.position_grad_ema = torch.cat((self.position_grad_ema[keep_mask], split_grad_ema), dim=0)\n\n        # --- 3. Densification (Cloning) ---\n        clone_mask = (self.learnable_params[:, 2] <= self.split_threshold_sigma) & (pos_grads_magnitude > self.densify_grad_threshold)\n        n_cloned = 0\n        if clone_mask.any():\n            n_cloned = clone_mask.sum().item()\n            clone_positions = self.positions.data[clone_mask]\n            clone_learnables = self.learnable_params.data[clone_mask]\n\n            self.learnable_params.data[clone_mask, 0] /= 2.0\n            \n            self.positions.data = torch.cat((self.positions.data, clone_positions), dim=0)\n            self.learnable_params.data = torch.cat((self.learnable_params.data, clone_learnables), dim=0)\n            self.position_grad_ema = torch.cat((self.position_grad_ema, self.position_grad_ema[clone_mask]), dim=0)\n\n        if n_pruned > 0 or n_split > 0 or n_cloned > 0:\n            print(f\"Pruned: {n_pruned}, Split: {n_split}, Cloned: {n_cloned}.\")\n            return True # Optimizer needs reset\n            \n        return False\n# --- NEW: Main Classifier Model ---\n\nclass MNISTVolumetricClassifier(nn.Module):\n    def __init__(self, initial_positions, initial_learnable_params, device, img_size=28):\n        super().__init__()\n        self.img_size = img_size\n        self.num_rays = img_size * img_size\n        self.wp_device = device\n        \n        # Core volumetric rendering layer\n        self.volumetric_layer = VolumetricSplattingLayer(\n            initial_positions, initial_learnable_params, device\n        )\n        \n        # Readout layer to classify the rendered feature map\n        self.readout_layer = nn.Linear(self.num_rays, 10)\n\n    def forward(self, x: torch.Tensor):\n        batch_size = x.shape[0]\n        \n        # 1. Generate a grid of rays for each image in the batch\n        rays_wp = self.generate_rays_for_batch(batch_size)\n        \n        # 2. Render the feature map using the volumetric layer\n        # The output will have shape (batch_size * num_rays)\n        rendered_features_flat = self.volumetric_layer(rays_wp)\n        \n        # 3. Reshape to (batch_size, num_rays) for the readout layer\n        rendered_features = rendered_features_flat.view(batch_size, self.num_rays)\n        \n        # 4. Classify the feature map\n        logits = self.readout_layer(rendered_features)\n        \n        return logits, rendered_features\n\n    def generate_rays_for_batch(self, batch_size: int):\n        \"\"\"Creates a grid of parallel rays for a batch of images.\"\"\"\n        total_rays = batch_size * self.num_rays\n        initial_rays_np = np.empty(total_rays, dtype=Ray.numpy_dtype())\n        \n        scale = 5.0 # How spread out the ray origins are in the XY plane\n        \n        for b in range(batch_size):\n            for j in range(self.img_size):\n                for i in range(self.img_size):\n                    idx = b * self.num_rays + j * self.img_size + i\n                    \n                    # Map pixel coords (i, j) to world space (ox, oy)\n                    ox = (i / (self.img_size - 1) - 0.5) * scale\n                    oy = (j / (self.img_size - 1) - 0.5) * scale\n                    \n                    initial_rays_np[idx]['origin'] = (ox, oy, -2.0) # Start rays further back\n                    initial_rays_np[idx]['dir'] = (0.0, 0.0, 1.0) # All point forward\n                    \n        return wp.array(initial_rays_np, dtype=Ray, device=self.wp_device)\n\n# --- Main script ---\n\n# Simulation setup\nnum_drops_initial = 8000 # More drops might be needed for this complex task\nbatch_size = 16\ntraining_steps = 5000\ndevice = wp.get_preferred_device()\ntorch_device = 'cuda' if wp.get_device(device).is_cuda else 'cpu'\nlambda_l1 = 1e-5 # L1 regularization on drop weights\n\n# --- Create Initial Drop Data ---\nrng = np.random.default_rng(42)\npositions_np = (rng.random(size=(num_drops_initial, 3), dtype=np.float32) - 0.5) * 8.0\npositions_np[:, 2] += 4.0 # Center the cloud along the Z axis\ninitial_weights = (rng.random(size=(num_drops_initial, 1), dtype=np.float32) - 0.5) * 0.1\ninitial_energies = np.ones((num_drops_initial, 1), dtype=np.float32)\ninitial_sigmas = np.full((num_drops_initial, 1), 0.5, dtype=np.float32)\nlearnable_data_np = np.hstack([initial_weights, initial_energies, initial_sigmas])\n\n# --- Load MNIST Data ---\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\ntrain_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ndata_iter = iter(train_loader)\n\n# --- Define the Model and Optimizer ---\nmodel = MNISTVolumetricClassifier(positions_np, learnable_data_np, device).to(torch_device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005, betas=(0.9, 0.99))\nloss_fn = nn.CrossEntropyLoss()\n\n# --- Training Loop ---\nprint(f\"\\n--- Starting Training for {training_steps} steps ---\")\n\nfor step in range(training_steps):\n    # Fetch a new batch of data\n    try:\n        images, labels = next(data_iter)\n    except StopIteration:\n        data_iter = iter(train_loader)\n        images, labels = next(data_iter)\n        \n    images, labels = images.to(torch_device), labels.to(torch_device)\n\n    optimizer.zero_grad()\n    \n    # --- Forward Pass ---\n    logits, rendered_features = model(images)\n    \n    # --- Loss Calculation ---\n    classification_loss = loss_fn(logits, labels)\n    l1_loss = lambda_l1 * torch.abs(model.volumetric_layer.learnable_params[:, 0]).sum()\n    total_loss = classification_loss + l1_loss\n    \n    # --- Backward Pass ---\n    # We need to manually handle the gradient flow from PyTorch back to Warp.\n    \n    # Step 1: Get the gradient of the loss w.r.t. the output of the volumetric layer.\n    # PyTorch's autograd does this for us when we call backward() on the loss.\n    # We need to retain the graph to allow backprop for the readout layer's params.\n    total_loss.backward(retain_graph=True) \n    \n    # The gradient we need is now in rendered_features.grad\n    seed_grad_tensor = rendered_features.grad\n    \n    # Step 2: Feed this gradient back into the Warp tape\n    seed_grad_wp = wp.from_torch(seed_grad_tensor.flatten().contiguous())\n    \n    # Use the tape and arrays stored in the volumetric layer during the forward pass\n    vol_layer = model.volumetric_layer\n    vol_layer.tape.backward(grads={vol_layer.outputs_wp: seed_grad_wp})\n    \n    # Step 3: Assign the calculated gradients from Warp to the nn.Parameters\n    vol_layer.learnable_params.grad = wp.to_torch(vol_layer.tape.gradients[vol_layer.learnable_params_wp])\n    vol_layer.positions.grad = wp.to_torch(vol_layer.tape.gradients[vol_layer.current_positions_wp])\n    \n    # Step 4: Manually add the L1 regularization gradient to the drop weights\n    with torch.no_grad():\n        l1_grad_weights = lambda_l1 * torch.sign(vol_layer.learnable_params.data[:, 0])\n        l1_grad_full = torch.zeros_like(vol_layer.learnable_params.grad)\n        l1_grad_full[:, 0] = l1_grad_weights\n        vol_layer.learnable_params.grad += l1_grad_full\n\n    # --- Optimizer Step ---\n    # The optimizer will now update the readout_layer params (from loss.backward())\n    # and the volumetric_layer params (from our manual gradient assignment).\n    optimizer.step()\n\n    # --- Update Layer State (Pruning/Densification) ---\n    if vol_layer.update_state(step):\n        # If drops were added/removed, reset the optimizer's state\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.005, betas=(0.9, 0.99))\n\n    if step % 50 == 0 or step == training_steps - 1:\n        # Calculate accuracy for logging\n        with torch.no_grad():\n            preds = torch.argmax(logits, dim=1)\n            accuracy = (preds == labels).float().mean()\n        print(f\"Step {step:04d}, Loss: {total_loss.item():.4f} (Class: {classification_loss.item():.4f}, L1: {l1_loss.item():.6f}), Acc: {accuracy:.2%}, Drops: {vol_layer.positions.shape[0]}\")\n\nprint(\"\\n--- Training complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T05:07:07.091731Z","iopub.execute_input":"2025-10-16T05:07:07.092216Z","iopub.status.idle":"2025-10-16T05:07:13.355019Z","shell.execute_reply.started":"2025-10-16T05:07:07.092185Z","shell.execute_reply":"2025-10-16T05:07:13.354086Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 9.91M/9.91M [00:00<00:00, 13.8MB/s]\n100%|██████████| 28.9k/28.9k [00:00<00:00, 340kB/s]\n100%|██████████| 1.65M/1.65M [00:00<00:00, 3.15MB/s]\n100%|██████████| 4.54k/4.54k [00:00<00:00, 8.71MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\n--- Starting Training for 5000 steps ---\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_37/3673858720.py:314: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n  seed_grad_tensor = rendered_features.grad\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/3673858720.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;31m# Step 2: Feed this gradient back into the Warp tape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0mseed_grad_wp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_grad_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;31m# Use the tape and arrays stored in the volumetric layer during the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'flatten'"],"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'flatten'","output_type":"error"}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}