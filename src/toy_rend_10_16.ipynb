import warp as wp
import numpy as np
import torch

# Initialize Warp
wp.init()

@wp.struct
class Drop:
    position: wp.vec3
    radius: wp.float32
    weight: wp.float32
    energy: wp.float32
    sigma: wp.float32

@wp.struct
class Ray:
    origin: wp.vec3
    dir: wp.vec3

# --- Differentiable Influence Function ---

@wp.func
def influence_func(sample_pos: wp.vec3, drop_pos: wp.vec3, sigma: wp.float32):
    dist_sq = wp.length_sq(sample_pos - drop_pos)
    sigma_sq = sigma * sigma
    return wp.exp(-dist_sq / (2.0 * sigma_sq + 1e-8))

# --- Volumetric Tracing Kernel with HashGrid ---

@wp.kernel
def volumetric_trace(
    # Scene Data
    grid: wp.uint64, # CHANGED: We now use a hash grid ID
    drop_positions: wp.array(dtype=wp.vec3),
    drop_learnable_params: wp.array(dtype=wp.float32, ndim=2),

    # Input/Output
    initial_rays: wp.array(dtype=Ray),
    outputs: wp.array(dtype=wp.float32),

    # Kernel Parameters
    num_steps: wp.int32,
    step_size: wp.float32,
    query_radius: wp.float32
):
    tid = wp.tid()
    ray = initial_rays[tid]
    accumulated_radiance = wp.float32(0.0)

    for i in range(num_steps):
        t = wp.float32(i) * step_size
        sample_pos = ray.origin + ray.dir * t

        # FIXED: Use the correct hash grid query function
        query = wp.hash_grid_query(grid, sample_pos, query_radius)
        candidate_index = wp.int32(0)
        
        local_radiance = wp.float32(0.0)

        # Loop over neighbors found by the query
        while wp.hash_grid_query_next(query, candidate_index):
            drop_weight = drop_learnable_params[candidate_index, 0]
            drop_energy = drop_learnable_params[candidate_index, 1]
            drop_sigma  = drop_learnable_params[candidate_index, 2]

            influence = influence_func(sample_pos, drop_positions[candidate_index], drop_sigma)
            contribution = influence * drop_weight * drop_energy
            local_radiance += contribution
        
        accumulated_radiance += local_radiance * step_size
    
    outputs[tid] = accumulated_radiance
@wp.kernel
def calculate_sparsity_cost(
    # Same inputs as the main kernel to trace the same paths
    grid: wp.uint64,
    initial_rays: wp.array(dtype=Ray),
    
    # Output
    total_neighbor_interactions: wp.array(dtype=wp.int32),

    # Kernel Parameters
    num_steps: wp.int32,
    step_size: wp.float32,
    query_radius: wp.float32
):
    tid = wp.tid()
    ray = initial_rays[tid]

    for i in range(num_steps):
        t = wp.float32(i) * step_size
        sample_pos = ray.origin + ray.dir * t

        query = wp.hash_grid_query(grid, sample_pos, query_radius)
        candidate_index = wp.int32(0)
        
        # Loop over neighbors and just count them
        while wp.hash_grid_query_next(query, candidate_index):
            # Atomically increment a global counter for each interaction
            wp.atomic_add(total_neighbor_interactions, 0, 1)

# --- Main script ---

# Simulation setup
num_drops = 400
num_initial_rays = 4096
training_steps = 150
device = wp.get_preferred_device()
torch_device = torch.device('cuda' if wp.get_device(device).is_cuda else 'cpu')

# --- Create Static Drop Properties ---
rng = np.random.default_rng(42)
positions_np = (rng.random(size=(num_drops, 3), dtype=np.float32) - 0.5) * 8.0
positions_np[:, 2] += 5.0
positions_device = wp.array(positions_np, dtype=wp.vec3, device=device)

# --- FIXED: Build HashGrid instead of BVH ---
print("Building HashGrid...")
grid_cell_size = 2.0 # This is a key parameter to tune. Should be ~2x your max query_radius
grid = wp.HashGrid(dim_x=128, dim_y=128, dim_z=128, device=device)
# The grid needs to be built with the particle positions
grid.build(points=positions_device, radius=grid_cell_size)
print(f"HashGrid built for {num_drops} drops.")


# --- Create LEARNABLE Drop Properties ---
initial_weights = (rng.random(size=(num_drops, 1), dtype=np.float32) - 0.5) * 0.1
initial_energies = np.ones((num_drops, 1), dtype=np.float32)
initial_sigmas = np.full((num_drops, 1), 0.5, dtype=np.float32)
learnable_data_np = np.hstack([initial_weights, initial_energies, initial_sigmas])
learnable_params_tensor = torch.tensor(learnable_data_np, requires_grad=True, device=torch_device)

# --- PyTorch Optimizer ---
optimizer = torch.optim.Adam([learnable_params_tensor], lr=0.01)
loss_fn = torch.nn.MSELoss()

# --- Create Target Signal ---
y_true_np = np.zeros(num_initial_rays, dtype=np.float32)
num_rays_side = int(np.sqrt(num_initial_rays))
for j in range(num_rays_side):
    for i in range(num_rays_side):
        idx = j * num_rays_side + i
        if idx >= num_initial_rays: continue
        u = (i / (num_rays_side - 1) - 0.5) * 2.0
        v = (j / (num_rays_side - 1) - 0.5) * 2.0
        distance_sq = u*u + v*v
        sigma_target = 0.5
        y_true_np[idx] = 5.0 * np.exp(-distance_sq / (2.0 * sigma_target**2.0))
y_true_tensor = torch.tensor(y_true_np, device=torch_device)

# --- Create Initial Rays ---
initial_rays_np = np.empty(num_initial_rays, dtype=Ray.numpy_dtype())
for j in range(num_rays_side):
    for i in range(num_rays_side):
        idx = j * num_rays_side + i
        if idx >= num_initial_rays: continue
        ox = (i / (num_rays_side - 1) - 0.5) * 5.0
        oy = (j / (num_rays_side - 1) - 0.5) * 5.0
        initial_rays_np[idx]['origin'] = (ox, oy, -1.0)
        initial_rays_np[idx]['dir'] = (0.0, 0.0, 1.0)
initial_rays_wp = wp.array(initial_rays_np, dtype=Ray, device=device)

# --- Training Loop ---
print(f"\n--- Starting Training for {training_steps} steps ---")

# Define your sparsity hyperparameter
lambda_l1 = 1e-4 # You'll need to tune this!

for step in range(training_steps):
    optimizer.zero_grad()
    
    learnable_params_wp = wp.from_torch(learnable_params_tensor)
    outputs_tensor = torch.zeros(num_initial_rays, dtype=torch.float32, device=torch_device)
    outputs_wp = wp.from_torch(outputs_tensor)

    # --- 1. Forward pass and rendering loss (same as before) ---
    tape = wp.Tape()
    with tape:
        wp.launch(
            kernel=volumetric_trace,
            dim=num_initial_rays,
            inputs=[
                grid.id,
                positions_device,
                learnable_params_wp,
                initial_rays_wp,
                outputs_wp,
                64,    # num_steps
                0.2,   # step_size
                1.0    # query_radius
            ],
            device=device
        )

    # Calculate the main rendering loss
    rendering_loss = loss_fn(outputs_tensor, y_true_tensor)

    # --- 2. Calculate the L1 Sparsity Loss ---
    # Access the weights, which are the first column of your learnable params
    drop_weights = learnable_params_tensor[:, 0]
    l1_loss = lambda_l1 * torch.abs(drop_weights).sum()
    
    # --- 3. Combine the losses ---
    total_loss = rendering_loss + l1_loss

    # --- 4. Backward Pass ---
    # First, get the gradients from the rendering loss via Warp's tape
    seed_grad_tensor = (2.0 / num_initial_rays) * (outputs_tensor - y_true_tensor)
    tape.backward(grads={outputs_wp: wp.from_torch(seed_grad_tensor)})
    
    # Copy the Warp gradients to the PyTorch tensor
    learnable_params_tensor.grad = wp.to_torch(learnable_params_wp.grad)
    
    # Now, use PyTorch's autograd to *add* the L1 loss gradient.
    # This is a key step: calling .backward() on the l1_loss will
    # accumulate its gradients on top of the existing rendering gradients.
    l1_loss.backward()

    # --- 5. Optimizer Step ---
    optimizer.step()
    
    if step % 10 == 0 or step == training_steps - 1:
        print(f"Step {step:03d}, Rendering Loss: {rendering_loss.item():.6f}, L1 Loss: {l1_loss.item():.6f}")

print("\n--- Training complete ---")
